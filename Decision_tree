{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPke7ka5I9Kqg5wMbiXm52o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"im0F0Vr_MqY6","executionInfo":{"status":"ok","timestamp":1683280837309,"user_tz":420,"elapsed":25607,"user":{"displayName":"rakesh puppala","userId":"02473426443691933781"}},"outputId":"cd84fbfd-86b6-42bf-86f5-641679cb3fc4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"URcDfd_4MrCx","executionInfo":{"status":"ok","timestamp":1683280883669,"user_tz":420,"elapsed":46365,"user":{"displayName":"rakesh puppala","userId":"02473426443691933781"}},"outputId":"da035a15-c7ea-4093-8479-a4ccd1e1e833"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=e5a5b682fee616b1d5bcae5af732486c0f35ee494c768464a40bd94095def5ad\n","  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.0\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.mllib.evaluation import MulticlassMetrics\n","from pyspark.sql.functions import col\n","import numpy as np\n","import os"],"metadata":{"id":"LfP8DE7CWn1a","executionInfo":{"status":"ok","timestamp":1683280883669,"user_tz":420,"elapsed":6,"user":{"displayName":"rakesh puppala","userId":"02473426443691933781"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["os.environ[\"SPARK_HOME\"] = \"/usr/local/lib/python3.10/dist-packages/pyspark\"\n","os.environ[\"HADOOP_HOME\"] = \"C:/winutils\"\n","\n","# Creating spark session\n","spark = SparkSession.builder.appName(\"Crime Analytics\").getOrCreate()\n","spark.sparkContext.setLogLevel(\"ERROR\")\n","\n","# Loading the dataset\n","KCDPFinal = spark.read.format(\"csv\").option(\"header\", True).option(\"inferSchema\", True).option(\"delimiter\", \",\").load(\"/content/drive/MyDrive/DBMS_project_final/Source Code/1-Datasets/KCPD_Crime_Data/KCcrimeForAnalytics.csv\").withColumnRenamed(\"Firearm_Used_Flag\", \"label\")\n","KCDPFinal\n","\n","# Create vector assembler for feature columns\n","VAssembler = VectorAssembler(inputCols=KCDPFinal.columns[1:19], outputCol=\"features\")\n","KCDPFinal = VAssembler.transform(KCDPFinal)\n","\n","# Split the crime dataset into training and testing data sets\n","trainingData, testingData = KCDPFinal.select(\"label\", \"features\").randomSplit([0.7, 0.3])\n","\n","# Using the training set for the model traning\n","from pyspark.ml.classification import DecisionTreeClassifier\n","DecisionTreeModel = DecisionTreeClassifier()\n","model = DecisionTreeModel.fit(trainingData)\n","\n","# Generate prediction from test dataset\n","CrimepredKC = model.transform(testingData)\n","\n","# Evuluate the accuracy of the model\n","evaluator = MulticlassClassificationEvaluator()\n","accuracy = evaluator.evaluate(CrimepredKC)\n","\n","# Show model accuracy\n","print(\"Accuracy:\", accuracy)"],"metadata":{"id":"kDFinzCvM6Bm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","data=pd.read_csv(\"/content/drive/MyDrive/output_folder/Reported_year=2010/part-00000-2b98d6cc-f2c0-4c81-b6af-d1e0f599ca21.c000.csv\")\n","data.drop([\"Unnamed: 24\",\"N\"],axis=1,inplace=True)\n","data.columns=[['Report_No','Reported_month', 'Reported_day',\n","       'Reported_hour', 'Reported_minute', 'From_year', 'From_month',\n","       'From_day', 'From_hour', 'From_minute', 'Offense', 'IBRS',\n","       'Description', 'Beat', 'Address', 'City', 'Zip_Code', 'Rep_Dist',\n","       'Area', 'DVFlag', 'Invl_No', 'Involvement', 'Race', 'Sex']]\n","data.drop(\"Report_No\",axis=1,inplace=True)\n","from sklearn.preprocessing import LabelEncoder\n","lb=LabelEncoder()\n","data['Description']=lb.fit_transform(data['Description'])\n","data['Address']=lb.fit_transform(data['Address'])\n","data['City']=lb.fit_transform(data['City'])\n","data['Rep_Dist']=lb.fit_transform(data['Rep_Dist'])\n","data['Area']=lb.fit_transform(data['Area'])\n","data['DVFlag']=lb.fit_transform(data['DVFlag'])\n","data['Involvement']=lb.fit_transform(data['Involvement'])\n","data['Race']=lb.fit_transform(data['Race'])\n","data['Sex']=lb.fit_transform(data['Sex'])\n","X = data.loc[:, data.columns != \"Area\"]\n","y = data[\"Area\"]"],"metadata":{"id":"SflzPm5sc-TZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = data.isna().sum()\n","print(count)"],"metadata":{"id":"t5gmaezTf3Jt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"],"metadata":{"id":"J7OGR3LJiCs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","Dt_alg = DecisionTreeClassifier(criterion='gini', random_state=0)\n","Dt_alg.fit(X_train, y_train)"],"metadata":{"id":"odW6ZZDNiPKm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred= Dt_alg.predict(X_test) "],"metadata":{"id":"1vNNADi8jNx5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred"],"metadata":{"id":"WMWcwEggk2Gh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test"],"metadata":{"id":"ng_uhV9FlWpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#testing_input()\n","#Area_prediction using sample input\n","output=Dt_alg.predict([[4.0, 15.0, 14.0, 43.0, 2010.0, 4.0, 15.0, 14.0, 43.0, 1352.0, 280.0, 0.0, 315.0, 66.0, 0.0, 64123.0, 17.0, 1.0, 1.0, 1.0, 2.0, 2.0,2.0]\n","])\n","print(output)"],"metadata":{"id":"LAhishGKk3FS"},"execution_count":null,"outputs":[]}]}